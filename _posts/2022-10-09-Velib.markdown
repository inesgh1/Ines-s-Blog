---
layout: post
title: Analyse des donn√©es Velib "Etude de cas"
date: 2022-10-09
description: C'est un projet qui etait propos√© comme etant un test technique pour le poste stagiaire data scientist
img: velib.png # Add image post (optional)
tags: [Programming,K-means,machine learning,interview,data science] # add tag
---
Ce projet est a la base un test technique pour le poste stagiare data scientist.
la 1 ere etape c'est de comprendre le jeu de donn√©e velib qui est du [opendata-paris](https://opendata.paris.fr/explore/dataset/velib-disponibilite-en-temps-reel/information/?disjunctive.name&disjunctive.is_installed&disjunctive.is_renting&disjunctive.is_returning&disjunctive.nom_arrondissement_communes)
apres on a...

## Plan
1. Acquisition des donn√©es V√©lib avec Python et Pandas
2. Stockage des donn√©es
3. Acquisition des donn√©es
4. Comprendre notre jeu de donn√©e
5. Classification automatique non supervis√©e
6. Data visualization

# 1.Acquisition des donn√©es V√©lib avec Python et Pandas

Plus concr√®tement, regardons en d√©tail ce que contiennent ces donn√©es avec Python. Pour ce faire, nous allons utiliser le module requests pour lancer une requ√™te sur l'API de V√©lib. Notre premi√®re requ√™te porte sur les caract√©ristiques des stations V√©libs
```
import requests

answer = requests.get("https://velib-metropole-opendata.smoove.pro/opendata/Velib_Metropole/station_information.json").json()
print(answer.keys())
```
On obtient en retour un fichier JSON, que l'on peut manipuler comme un dictionnaire Python, avec 3 clefs : lastUpdatedOther l'indication de la date de derni√®re mise √† jour des donn√©es, ttl la dur√©e de vie des donn√©es avant de devenir obsol√®te et enfin data les donn√©es proprement d√Ætes.

Pour manipuler ces donn√©es, nous allons utiliser le module Pandas. C'est un outil puissant d'analyse de donn√©es dont la base est l'objet DataFrame

```
import pandas as pd

df_1 = pd.DataFrame(answer["data"]["stations"])
df_1.head()
```
On voit que pour chaque station, nous disposons de son nom, de son identifiant unique station_id et de sa position en latitude lat et longitude lon. Ce sont des donn√©es √† dur√©e de vie longue que nous allons garder sous le bras. On ne s'attend pas √† ce que des stations se d√©placent ou bien changent de nom toutes les 5 minutes.

Une requ√™te que nous allons effectuer tr√®s r√©guli√®rement concerne l'occupation des stations :
```
answer = requests.get("https://velib-metropole-opendata.smoove.pro/opendata/Velib_Metropole/station_status.json").json()
df_2 = pd.DataFrame(answer["data"]["stations"])
df_2.head()
```
Pour chaque station, nous obtenons en temps r√©el (les donn√©es sont mises √† jour toutes les minutes) le nombre de v√©libs mis √† disposition, le nombre de places disponibles et m√™me la d√©composition entre le nombre de v√©los m√©caniques et √©lectriques.
  Congrats üéâ:Mission accomplie nous avons recuperer les donn√©e en utilisant API et python.
  
  # 2.Stockage des donn√©es

Maintenant que nous savons r√©cup√©rer les donn√©es V√©lib, nous allons pouvoir les stocker sous la forme d'une base de donn√©es persistante SQLITE3. Pour faire simple, il s'agit d'une base de donn√©es dite l√©g√®re (mais puissante !) qui se pr√©sente sous la forme d'un simple fichier. C'est un format tr√®s pratique pour de petits projets comme le notre ou pour la phase de d√©veloppement de plus gros projets. Avec Pandas, la proc√©dure est limpide :
```
# On supprimse les donn√©es inutiles
del df_1["stationCode"]
del df_1["rental_methods"]
del df_2["numBikesAvailable"]
del df_2["num_bikes_available_types"]
del df_2["numDocksAvailable"]
del df_2["is_installed"]
del df_2["is_returning"]
del df_2["is_renting"]
del df_2["last_reported"]

# On cr√©e un marqueur temporel
time_stamp = pd.Timestamp.now()
df_2["time_stamp"] = time_stamp

# On enregistre sous forme de base SQLITE
df_1.to_sql("localisation", "sqlite:///data.db", if_exists="replace")
df_2.to_sql("stations", "sqlite:///data.db", if_exists="append")

```
La commande se lit : j'envoie le DataFrame df_1 vers SQL sous le nom de table localisation et dans la base SQLITE data.db. Si la table existe alors on la remplace. Pour les donn√©es en temps r√©el, on ajoute un marqueur temporel qui permet de garder en m√©moire l'heure d'acquisition des donn√©es. Notez l'option if_exists="append" : √† chaque nouvelle acquisition, on ajoute de nouvelles lignes √† la table. Concr√®tement, le marqueur temporel ressemble √† √ßa
```
time_stamp
```
```
output:Timestamp('2022-10-09 01:38:18.399282')
```
Le marqueur retient la date et l'heure pr√©cise √† laquelle j'√©cris ces lignes. Et ce sera la m√™me chose pour nos donn√©es d'occupation des stations V√©lib.

# 3. Acquisition des donn√©es
Il ne nous reste plus qu'√† automatiser l'acquisition de donn√©es toutes les minutes. Il existe un module python pour √ßa qui s'appelle APScheduler. Ce module permet l'automatisation et la planification de t√¢ches, et nous utiliserons l'objet BlockingScheduler. Son utilisation est la suivante :
```
from apscheduler.schedulers.blocking import BlockingScheduler

sched = BlockingScheduler()

@sched.scheduled_job("interval", seconds=5)
def print_date():
    time_stamp = pd.Timestamp.now()
    print(time_stamp)

sched.start()
```
Avec le d√©corateur @sched.scheduled_job("interval", seconds=5), on indique que la fonction doit √™tre appel√©e r√©guli√®rement avec un intervalle de temps de 5 secondes.

Nous avons maintenant tous les ingr√©dients pour lancer une acquisition de donn√©es. 
# 4. Comprendre notre jeu de donn√©e
Nous allons maintenant pouvoir jouer avec nos belles donn√©es toutes fraiches. Commen√ßons par importer les deux tables dans deux DataFrames distincts









